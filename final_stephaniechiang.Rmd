---
title: "Final Examination"
subtitle: "DATA 605"
author: "Stephanie Chiang"
date: "Fall 2025"
output: pdf_document
---

Instructions:

You are required to complete this take-home final examination by the end of the last week of class. Your solutions should be uploaded in pdf format as a knitted document (with graphs, content, commentary, etc. in the pdf). This project will showcase your ability to apply the concepts learned throughout the course.

The dataset you will use for this examination is provided as retail data.csv, which contains the following variables:

- Product_ID: Unique identifier for each product.
- Sales: Simulated sales numbers (in dollars).
- Inventory_Levels: Inventory levels for each product.
- Lead_Time_Days: The lead time in days for each product.
- Price: The price of each product.
- Seasonality_Index: An index representing seasonality.

***

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

library(tidyverse)

set.seed(101)
```

```{r import}
retail <- read.csv("synthetic_retail_data.csv")
```

# Problem 1: Business Risk and Revenue Modeling 

Context: You are a data scientist working for a retail chain that models sales, inventory levels, and the impact of pricing and seasonality on revenue. Your task is to analyze various distributions that can describe sales variability and forecast potential revenue.

## Part 1: Empirical and Theoretical Analysis of Distributions (5 Points)

Task:

1. Generate and Analyze Distributions:

- X ~ Sales: Consider the Sales variable from the dataset. Assume it follows a Gamma distribution and estimate its shape and scale parameters using the fitdistr function from the MASS package.

**ANSWER:**

For a gamma distribution of the Sales variable, the shape parameter is 1.835. Scale is the inverse of the rate parameter 0.0029, or 347.0997.

```{r}
library(MASS)

fit_gamma <- fitdistr(retail$Sales, "gamma")
fit_gamma

scale_gamma <- 1 / fit_gamma$estimate["rate"]
scale_gamma
```

- Y ~ Inventory Levels: Assume that the sum of inventory levels across similar products follows a Lognormal distribution. Estimate the parameters for this distribution.

**ANSWER:**

For a Lognormal distribution of the inventory levels, the mean of the log is 6.133 and the standard deviation of the log is 0.3633.

```{r}
fit_ln <- fitdistr(retail$Inventory_Levels, "lognormal")
fit_ln
```

- Z ~ Lead Time: Assume that Lead_Time_Days follows a Normal distribution. Estimate the mean and standard deviation.

**ANSWER:**

For a normal distribution of lead time, the mean is 6.8343 and the standard deviation is 2.0832.

```{r}
fit_n <- fitdistr(retail$Lead_Time_Days, "normal")
fit_n
```

2. Calculate Empirical Expected Value and Variance:

- Calculate the empirical mean and variance for all three variables.

**ANSWER:**

```{r}
empirical <- retail |>
  summarise(
    mean_sales = round(mean(Sales, na.rm = TRUE), digits = 2),
    var_sales = round(var(Sales, na.rm = TRUE), digits = 2),
    mean_inv = round(mean(Inventory_Levels, na.rm = TRUE), digits = 2),
    var_inv = round(var(Inventory_Levels, na.rm = TRUE), digits = 2),
    mean_lead = round(mean(Lead_Time_Days, na.rm = TRUE), digits = 2),
    var_lead = round(var(Lead_Time_Days, na.rm = TRUE), digits = 2)
  )

empirical <- empirical |>
  pivot_longer(
    cols = 0:6, 
    names_to = "metric",
    values_to = "val"
  )

print(empirical)
```

- Compare these empirical values with the theoretical values derived from the estimated distribution parameters.

**ANSWER:**

For the Sales variable:

- estimated gamma distribution mean is shape / rate
- estimated gamma variance is shape / rate^2

For the Inventory variable:

- estimated lognormal distribution mean is calculated by inversing the natural log value (or taking exp) of meanlog + sdlog^2 / 2)
- estimated lognormal variance is (exp(sigma^2) - 1) * exp(2*mu + sigma^2)

For the Lead Time variable:

- estimated mean is the given mean
- estimated variance is the given standard deviation squared

The comparing the estimated values below with the empirical values in the previous problem:

- the gamma distribution appears appropriate for the Sales variable, since the means are equal and the variances are close though the estimate is slightly wider
- the lognormal distribution for the Inventory variable is the furthest from the empirical calculations, the estimated mean is somewhat higher but the variance is much larger
- the normal distribution for Lead Time is calculated the same way as for the empirical data, so the values are the same

```{r}
estimated <- tibble(
  metric = c("mean_sales_gamma", "var_sales_gamma", "mean_inv_ln", "var_inv_ln", "mean_lead_n", "var_lead_n"),
  value = c(
    round(fit_gamma$estimate["shape"] / fit_gamma$estimate["rate"], digits = 2),
    round(fit_gamma$estimate["shape"] / (fit_gamma$estimate["rate"]^2), digits = 2),
    round(exp(fit_ln$estimate["meanlog"] + (fit_ln$estimate["sdlog"]^2 / 2)), digits = 2), 
    round((exp(fit_ln$estimate["sdlog"]^2) - 1) * exp(2*fit_ln$estimate["meanlog"] + fit_ln$estimate["sdlog"]^2), digits = 2),
    round(fit_n$estimate["mean"], digits = 2), 
    round(fit_n$estimate["sd"]^2, digits = 2)
  )
)

estimated
```


## Part 2: Probability Analysis and Independence Testing (5 Points)

Task:

1. Empirical Probabilities: For the Lead_Time_Days variable (assumed to be normally distributed), calculate the following empirical probabilities:

- P(Z > mu | Z > mu - sigma)

**ANSWER:**

```{r}
mu <- mean(retail$Lead_Time_Days, na.rm = TRUE)
sigma <- sd(retail$Lead_Time_Days, na.rm = TRUE)

# helper function to get the probability of Z being greater than a given value
prob_z_greater <- function(x) 1 - pnorm(x, mean = mu, sd = sigma)

# conditional probability of A | B simplifies to P(A) / P(B)
prob_z_greater(mu) / prob_z_greater(mu - sigma)
```

- P(Z > mu + sigma | Z > mu)

**ANSWER:**

```{r}
prob_z_greater(mu + sigma) / prob_z_greater(mu)
```

- P(Z > mu + 2sigma | Z > mu)

**ANSWER:**

```{r}
prob_z_greater(mu + 2*sigma) / prob_z_greater(mu)
```

2. Correlation and Independence:

- Investigate the correlation between Sales and Price. Create a contingency table using quartiles of Sales and Price, and then evaluate the marginal and joint probabilities.

**ANSWER:**

At 0.1027, the correlation calculated below is positive but appears weak.

Then, by breaking the values into quartile bins, the following are created:

- contingency table that shows the frequencies of the combinations of the Sales (in the rows) and the Prices (in the columns)
- joint probabilities table that shows the probability of an observation falling in both a Sales and Price quartile
- marginal probabilities table that shows the probability of one of either Sales or Price occurring independently, without regard to the other

```{r}
cor(retail$Sales, retail$Price)

retail_quartiles <- retail |>
  mutate(
    Sales_Q = cut(Sales,
                  breaks = quantile(Sales, probs = seq(0, 1, 0.25), na.rm = TRUE),
                  include.lowest = TRUE,
                  labels = c("Q1", "Q2", "Q3", "Q4")),
    Price_Q = cut(Price,
                  breaks = quantile(Price, probs = seq(0, 1, 0.25), na.rm = TRUE),
                  include.lowest = TRUE,
                  labels = c("Q1", "Q2", "Q3", "Q4"))
  )

# contingency table
cont_table <- table(retail_quartiles$Sales_Q, retail_quartiles$Price_Q)
cont_table

# joint probabilities
joint_table <- prop.table(cont_table)
joint_table

# marginal probabilities
sales_marg <- prop.table(margin.table(cont_table, 1))
sales_marg

price_marg <- prop.table(margin.table(cont_table, 2))
price_marg
```

- Use Fisher’s Exact Test and the Chi-Square Test to check for independence between Sales and Price. Discuss which test is most appropriate and why.

**ANSWER:**

Fisher’s Exact Test is only good for small tables, so `fisher.test()` actually errors when running on this contingency table. Pearson's Chi-square Test is works for larger contingency tables like this one, but is more of an approximation.

The P-value of 0.8514 is very large, we can fail to reject the null hypothesis - we can assume the independence of the variables. 

```{r}
chisq.test(cont_table)
```


# Problem 2: Advanced Forecasting and Optimization (Calculus) in Retail 

Context: You are working for a large retail chain that wants to optimize pricing, inventory management, and sales forecasting using data-driven strategies. Your task is to use regression, statistical modeling, and calculus-based methods to make informed decisions.

## Part 1: Descriptive and Inferential Statistics for Inventory Data (5 Points)

Task:

1. Inventory Data Analysis:

- Generate univariate descriptive statistics for the Inventory_Levels and Sales variables.

**ANSWER:**

Below are the univariate descriptive statistics of the cenral tendencies for Inventory and Sales:

- mean
- median
- min
- max
- quartiles
- standard deviation
- IQR for interquartile range

```{r}
summary(retail$Inventory_Levels)
sd(retail$Inventory_Levels)
IQR(retail$Inventory_Levels)

summary(retail$Sales)
sd(retail$Sales)
IQR(retail$Sales)
```

- Create appropriate visualizations such as histograms and scatterplots for Inventory_Levels, Sales, and Price.

**ANSWER:**

```{r}
# Inventory_Levels
ggplot(retail, aes(x=Inventory_Levels)) +
  geom_histogram() +
  labs(title = "Inventory Levels histogram") +
  theme_minimal()

# Sales
ggplot(retail, aes(x=Sales)) +
  geom_histogram() +
  labs(title = "Sales histogram") +
  theme_minimal()

# Price
ggplot(retail, aes(x=Price)) +
  geom_histogram() +
  labs(title = "Price histogram") +
  theme_minimal()
```

```{r}
ggplot(retail, aes(x=Inventory_Levels, y=Sales)) +
  geom_point() +
  labs(title = "Inventory Levels vs Sales") +
  theme_minimal()

ggplot(retail, aes(x=Price, y=Sales)) +
  geom_point() +
  labs(title = "Price vs Sales") +
  theme_minimal()
```

- Compute a correlation matrix for Sales, Price, and Inventory_Levels.

**ANSWER:**

```{r}
cor(retail[, c("Sales", "Price", "Inventory_Levels")],
    use = "complete.obs")
```

- Test the hypotheses that the correlations between the variables are zero and provide a 95% confidence interval.

**ANSWER:**

The correlations are tested with 95% confidence intervals for each combination below. Each pair is close to 0.

```{r}
cor.test(retail$Sales, retail$Price)
cor.test(retail$Sales, retail$Inventory_Levels)
cor.test(retail$Price, retail$Inventory_Levels)
```

2. Discussion:

- Explain the meaning of your findings and discuss the implications of the correlations for inventory management. Would you be concerned about multicollinearity in a potential regression model? Why or why not?

**ANSWER:**

The tests above indicate:

- all correlations are small
- all p-values are larger than 0.05
- all confidence intervals include 0

This means there are no significant correlations between Sales, Price nor Inventory Levels. There is also no expected multicollinearity for regression modeling due to the low correlation values. 

## Part 2: Linear Algebra and Pricing Strategy (5 Points)

Task:

1. Price Elasticity of Demand:

- Use linear regression to model the relationship between Sales and Price (assuming Sales as the dependent variable).

**ANSWER:**

```{r}
mod_22 <- lm("Sales ~ Price", data = retail)
summary(mod_22)
```

- Invert the correlation matrix from your model, and calculate the precision matrix.

**ANSWER:**

```{r}
cor_22 <- cor(retail[, c("Sales", "Price")],
    use = "complete.obs")

solve(cor_22)
```

- Discuss the implications of the diagonal elements of the precision matrix (which are variance inflation factors).

**ANSWER:**

The diagonal numbers (upper left, lower right) in the precision matrix are VIFs for Sales and Price and are another measure multicollinearity.

Since both diagonal values are about 1.01, there is no multicollinearity. This means Price appears independent on Sales.

- Perform LU decomposition on the correlation matrix and interpret the results in the context of price elasticity.

**ANSWER:**

The LU decomposition below shows how:

- The L (lower) matrix shows little dependence of Price on Sales
- The U (upper) matrix shows little dependence of Sales on Price

Price elasticity refers to how Sales changes in relation to Price changes. So since there is no strong causal or structural link, Sales is not expected to significantly change if prices change - meaning low elasticity.

```{r}
library(pracma)

lu(cor_22)
```

## Part 3: Calculus-Based Probability & Statistics for Sales Forecasting (5 Points)

Task:

1. Sales Forecasting Using Exponential Distribution:

- Identify a variable in the dataset that is skewed to the right (e.g., Sales or Price) and fit an exponential distribution to this data using the fitdistr function.

**ANSWER:**

Based on the histograms from a previous section, Sales has a right skew, so the exponential distribution is fitted on Sales:

```{r}
fit_exp <- fitdistr(retail$Sales, "exponential")
fit_exp
```

- Generate 1,000 samples from the fitted exponential distribution and compare a histogram of these samples with the original data's histogram.

**ANSWER:**

Both histograms are right-skewed but the simulated samples are "cleaner" with larger axes (due to the larger sample size) and a longer, smoother tail.

```{r}
exp_samples <- rexp(1000, rate = fit_exp$estimate["rate"])

ggplot(data = data.frame(exp_samples), aes(x = exp_samples)) +
  geom_histogram()
```

- Calculate the 5th and 95th percentiles using the cumulative distribution function (CDF) of the exponential distribution.

**ANSWER:**

The CDF of the exponential distribution is calculated using `qexp()`.

```{r}
exp_lower <- qexp(0.05, rate = fit_exp$estimate["rate"])
exp_lower

exp_upper <- qexp(0.95, rate = fit_exp$estimate["rate"])
exp_upper
```

- Compute a 95% confidence interval for the original data assuming normality and compare it with the empirical percentiles.

**ANSWER:**

The below calculations, for the empirical and normal distributions are compared in a simple table, along with the exponential. The normal CI underestimates the lower bound because the distribution is heavily right-skewed. This results in an unrealistic negative lower bound, and a much lower value for the upper bound compared to the empirical data.

```{r}
mu_hat <- mean(retail$Sales, na.rm = TRUE)
sigma_hat <- sd(retail$Sales, na.rm = TRUE)

ci_lower <- mu_hat - 1.96 * sigma_hat
ci_upper <- mu_hat + 1.96 * sigma_hat

empirical_lower <- quantile(retail$Sales, 0.025, na.rm = TRUE)
empirical_upper <- quantile(retail$Sales, 0.975, na.rm = TRUE)

data.frame(
  Method = c("Normal CI", "Empirical Percentiles", "Exponential CI"),
  Lower = c(ci_lower, empirical_lower, exp_lower),
  Upper = c(ci_upper, empirical_upper, exp_upper)
)
```

2. Discussion:

- Discuss how well the exponential distribution models the data and what this implies for forecasting future sales or pricing. Consider whether a different distribution might be more appropriate.

**ANSWER:**

The exponential distribution fits this Sales data well (or at least better than normality). The bounds are slightly wider but the right skew is handled and risk is low of underestimating or overestimating for future sales. 


## Part 4: Regression Modeling for Inventory Optimization (10 Points)

Task:

1. Multiple Regression Model:

- Build a multiple regression model to predict Inventory_Levels based on Sales, Lead_Time_Days, and Price.
- Provide a full summary of your model, including coefficients, R-squared value, and residual analysis.

**ANSWER:**

The multiple linear regression below models the effects of Sales, Lead_Time_Days, and Price as the x values and Inventory_Levels as the y, or outcome variable, with residual plots. 

Coefficients: Lead_Time_Days has a positive, larger coefficient, representing an increase in Inventory_Levels. Sales and Price are negative and should decrease Inventory_Levels but the values are small, so the effects should be minimal.

R-squared: Both multiple R-squared and adjusted R-squared are small, so x variables generally have weak influence on the y. 

Residual plots: The Residuals vs Fitted are a randomly scattered cloud around 0 and the QQ plot sticks close the line. Overall the assumptions of linear regression appear satisfied.

```{r}
mod_41 <- lm("Inventory_Levels ~ Sales + Lead_Time_Days + Price", data = retail)
summary(mod_41)
plot(mod_41)
```

2. Optimization:

- Use your model to optimize inventory levels for a peak sales season, balancing minimizing stockouts with minimizing overstock. 

**ANSWER:**

Using Sales, the peak sales season can be estimated based on the 90% percentile of historical data. Then, the multiple linear regression model above is used to make the predictions.

For the baseline amount of stock, we just take the predicted mean sales with `pred_41[, "fit"]`.

For a buffer to handle uncertain demand, we can add that to the product of the standard deviation of the residuals and the z-score. This would represent the possible error in prediction.

The following predictions should minimize both overstocking and out-of-stock times. 

```{r}
peak_sales_est <- retail |>
  summarize(Peak_Demand = quantile(Sales, 0.90))

pred_41 <- predict(mod_41, newdata = retail, interval = "prediction")

Inventory_opt <- pred_41[, "fit"] + qnorm(0.95) * summary(mod_41)$sigma
Inventory_opt
```

